# Real-time Whisper Transcription with Llama Chat

This project provides a single script for real-time audio transcription using Whisper and immediately sending the transcription to a Llama model for a response.

## Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Run the main script:
```bash
python main.py
```

## Usage

Once the script is running, it will start recording audio from your default microphone. As you speak, transcriptions will appear in the console, followed by responses generated by the Llama model based on those transcriptions.

Press `Ctrl+C` to stop the recording and the application.

## Functionality

- Real-time audio recording and processing
- Whisper transcription of audio chunks
- Sending transcriptions to Llama for text generation
- Displaying both the transcription and Llama's response in the console

## Notes

- The Llama model (`meta-llama/Llama-3.2-1B`) is loaded with `device_map="auto"`, which attempts to use available GPU resources (like MPS on macOS or CUDA on other systems). Ensure you have the necessary hardware and drivers.
- Transcription is set to translate to Chinese (`language="zh", task="translate"`). You can change this in the `main.py` file if needed.
- The Llama prompt is a simple f-string. For more complex conversational interactions, you would need a more sophisticated prompting strategy.
- The `max_new_tokens` for Llama is set to 50. Adjust this based on the desired length of responses.

## Troubleshooting

- If you encounter issues with audio recording, check your microphone settings and ensure `sounddevice` is configured correctly.
- Model loading can be memory-intensive. If you run into memory errors, consider using a smaller Llama model or ensuring you have sufficient RAM/VRAM.
- The `attention_mask` warning from transformers is expected and generally harmless for this use case. 